# DiffEdit_Implementation
To showcase and further develop my knowledge of Generative AI techniques, particularly with Stable Diffusion, I have implemented the ideas from DiffEdit: Diffusion-based Semantic Image Editing with Mask Guidance (Zhu et al., 2022) in this notebook. This implementation leverages diffusion models for semantic image editing, allowing for targeted modifications of images based on user-defined masks and textual prompts.

While the notebook is functional and produces reasonable results, there remains room for improvement in both performance and image quality.

One example is that there are models that are designed specifically for taking a mask and adding the edit, which create better images, but I wanted to create the whole process of mask creation and processing myself.

This project is a step towards mastering GenAI techniques, demonstrating my practical knowledge of Stable Diffusion in the context of semantic image editing.

![image](https://github.com/user-attachments/assets/6a0a7318-762b-44a7-b1e3-26e7be9d60ec)

![image](https://github.com/user-attachments/assets/bfa9b4d8-a053-46b5-8784-8e64f5d02f09)
